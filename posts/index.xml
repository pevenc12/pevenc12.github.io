<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on blog.p</title><link>https://pevenc12.github.io/posts/</link><description>Recent content in Posts on blog.p</description><generator>Hugo -- gohugo.io</generator><language>zh-tw</language><copyright>© Peven</copyright><lastBuildDate>Sat, 21 Jan 2023 23:06:58 +0800</lastBuildDate><atom:link href="https://pevenc12.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>[Summary] Just Use a Monorepo</title><link>https://pevenc12.github.io/posts/summary-just-use-a-monorepo/</link><pubDate>Sat, 21 Jan 2023 23:06:58 +0800</pubDate><guid>https://pevenc12.github.io/posts/summary-just-use-a-monorepo/</guid><description>Link: Just use a monorepo
Buttondown, a newsletter service, recently migrated their projects from separate microrepositories to a single monorepo. They strongly recommends that a software business use monorepo as early as possible. The followings are pros and cons in the article and its reference.
Pros:
API rolls out smoothly with up-to-date documentation. There should be no conflict between front-end and backend of the system. Avoid context-switching among different workspaces, which might have slightly different configurations.</description></item><item><title>[Summary] How Discord Stores Billions of Messages</title><link>https://pevenc12.github.io/posts/summary-how-discord-stores-billions-of-messages/</link><pubDate>Thu, 12 Jan 2023 00:17:04 +0800</pubDate><guid>https://pevenc12.github.io/posts/summary-how-discord-stores-billions-of-messages/</guid><description>Link: HOW DISCORD STORES BILLIONS OF MESSAGES
The article discusses how Discord chose and migrated to new database in order to deal with tons of stored messages. The article was published in 2017 and provided insights about data storage. Having an idea about how Cassandra read/write data is helpful to understand the content. Cassandra uses a storage structure similar to Log-Structured Merge Tree, which is known for its high performance in writing but less efficient in reading, comparing to B-Tree.</description></item><item><title>不要過度 Indexing，看看這個反例</title><link>https://pevenc12.github.io/posts/dont-over-index/</link><pubDate>Tue, 03 May 2022 23:20:11 +0800</pubDate><guid>https://pevenc12.github.io/posts/dont-over-index/</guid><description>本文的舉例取自 PostgreSQL Optimizer Methodology 內容主要在 PostgreSQL 的 Query Planner 如何最佳化以及其遇到的痛點，值得一看。
文中提到 PostgreSQL 對於 row-count estimate 有改善的空間時，提到了以下範例：
SELECT * FROM foo WHERE a = 1 ORDER BY b LIMIT 1; 假設資料庫已經對 a 和 b 都分別做 indexing 的話，Query Planner 可能會產出以下兩種 Plan：
利用 index scan 去找出 a = 1 的 tuples，再一一比較找出含最小值 b 的 tuple 利用 index scan 依照 b 的大小順序一一把 tuples 拉出來看，再找含 a = 1 的 tuple 如果這個 table 只有幾個 tuples 的 a 值等於 1 的話，那就很適合使用第一個方法，只需要幾次的 random access 即可找到所求。但是，如果有大量的 tuples 的 a 值為 1 的話，會因為 random access 的次數過多而導致效能變差，反而方法二可能會好一些。</description></item><item><title>PostgreSQL：淺入淺出 EXPLAIN（下）</title><link>https://pevenc12.github.io/posts/postgresql-explain-explained-join/</link><pubDate>Sat, 12 Feb 2022 19:50:15 +0800</pubDate><guid>https://pevenc12.github.io/posts/postgresql-explain-explained-join/</guid><description>前言 在一個 query 中如果會關聯到兩個以上的 relation（表），就需要進行 JOIN。在 PostgreSQL 中有三種 JOIN 行為（大多數的關聯式資料庫也分為這三種）：Nested Loop Join、Merge Join、Hash Join。
JOIN 先簡單加入一些資料當作起手式。假設在一個購物網站中，要關聯使用者資料與訂單資料。首先是使用者（user）資料：
u_id name phone 1 Peven 0912345678 2 Jack 0922345678 3 Ben 0932345678 再來是訂單（order）資料：
o_id amount payment_method customer_id 1 100 CASH 1 2 200 CREDIT_CARD 2 3 300 CASH 3 4 150 DEBIT_CARD 1 5 150 CREDIT_CARD 3 並且下 query：
SELECT * FROM user JOIN order ON user.u_id = order.customer_id; 以下提到的 left relation 與 right relation 是 query planner 在 runtime 決定的，不一定是指 user 或是 order。</description></item><item><title>PostgreSQL：垃圾回收機制 VACUUM</title><link>https://pevenc12.github.io/posts/postgresql-vacuum-introduction/</link><pubDate>Tue, 30 Nov 2021 22:03:55 +0800</pubDate><guid>https://pevenc12.github.io/posts/postgresql-vacuum-introduction/</guid><description>前陣子在工作上遇到了資料庫佔用太多空間所以要清理的情境，便順手研究了一下 PostgreSQL 內的垃圾回收機制—— VACUUM 。
為什麼需要垃圾回收 在討論為什麼要進行垃圾回收之前，要先介紹一下 PostgreSQL 內部實作的 MVCC（Multi Version Concurrency Control）機制：
資料庫內部有一個 counter ，負責發給每個 transaction 一個 transaction ID（XID），每次發完之後會將 counter 加一。在 transaction 內完成 create 、 update 、 delete 等行為後，會將該 XID 更新到每一筆有動到的 tuple 裡，如此讓資料也有版號。當其他 transaction 要觸碰這些被更動過的 tuple 時，就會拿著自己的 XID 去跟 tuple 上的 XID 做比較，如果自己的版號較新，就能完整讀到所有資料，反之如果自己的版號較舊，就會讀不到。
由此可知，被刪除的 tuple 不會馬上從資料庫內消失，而是會被註記於某個 XID 以後就再也讀不到。因此，資料庫必須進行垃圾回收才能釋放空間並重複利用。
VACUUM 機制 回收儲存空間 在 PostgreSQL 中，有兩種回收的行為： VACUUM 與 VACUUM FULL ，前者會將同一個 table 的空間回收並供該 table 繼續使用，並且在過程中並不會有使用到任何 lock 。後者則是會新建 table 並且將 tuples 重新寫入，過程中會使用 exclusive lock ，多餘的空間會釋出並還給作業系統。</description></item><item><title>Backend：處理時間、時區的幾個提醒</title><link>https://pevenc12.github.io/posts/time-and-timezone-reminder/</link><pubDate>Sun, 15 Aug 2021 18:10:14 +0800</pubDate><guid>https://pevenc12.github.io/posts/time-and-timezone-reminder/</guid><description>前言 現代的軟體會有來自世界各地的使用者。在處理時間、時區的時候要格外小心，否則可能會造成使用者誤會、應用程式錯誤。本文列舉幾個在開發上需要注意的地方以避免這類的錯誤並提升程式的正確性與安全性。文中以 python 為程式語言做示範。
時區轉換 時間資料會同時出現在三個地方，包括：資料庫、資料系統（前端、後端、mobile）以及使用者的介面（web、app）。在使用者介面上大部分會將時間轉換至該使用者所在的時區，但是在資料庫與資料系統中會有一些不同的做法。
資料庫 vs 時區 在 PostgreSQL 與 MySQL 中存入包含時區的 timestamp 時（MySQL 在 8.0 以後的版本才支援），系統會先將該時間轉換回 UTC 時區再儲存。在讀取資料（SELECT）的時候另外在 SQL 中加入 AT TIME ZONE 指令即可將資料庫內的 timestamp 轉為指定的時區。使用 UTC 時區儲存有下列兩個好處：
資料庫移動更彈性 在 MySQL 中的 timestamp 格式是不包含時區資訊的。假如資料庫採用當地時間進行存取，在之後資料庫要進行搬遷、複製（replication）到其他資料中心而且不在相同的時區時，資料會產生錯亂。反之，若統一使用 UTC 時區儲存資料的話，即使資料庫的預設時間更改，也不會影響到原本時間資料的正確性。
解決變動時區的問題，例如夏令時間 在美國與部分歐洲國家中，會在春天時將時間調快一個小時，並在秋天時調回來。以2021年的美國夏令時間為例，會將3月14日凌晨兩點會往後調到凌晨三點，所以當天會有一個小時（02:00 - 03:00）完全消失。在11月7日會將凌晨兩點調回凌晨一點，所以會有一個小時重複出現（01:00 - 02:00），如果只以當地時間來儲存資料，可能會出現誤會。因此，一律儲存為 UTC 時區比較準確。
資料系統 vs 時區 在資料系統中進行計算、比較時間先後的時候，通常都統一使用 UTC 時區進行。但是如果資料經過計算後是會呈現在使用者面前，或是該服務會與使用者所在的時區有關，就必須要在計算前先將時間轉換到使用者所在的時區。例如在餐廳訂位系統中，消費者在查詢可訂位的時段時，系統依據餐廳營業的時間加上該餐廳所在的時區等資料計算出所有可訂位的時段，最後回傳給消費者選擇。
確認套件的作用 各個程式語言對於時間、時區的處理都有很完整的支援，在使用前要注意對於時區的轉換。以 python 為例，處理時間的套件就有 datetime、arrow 等等。筆者習慣使用 datetime 處理時間的計算以及 pytz 處理時區。各套件對時區轉換的函式有不同的作用，有些會將時間一同轉換過去該時區，有些則只是在時間加上時區資訊，使用時要注意使用情境不要混用。舉例如下：
import datetime from pytz import timezone # datetime.</description></item><item><title>PostgreSQL：淺入淺出 EXPLAIN（上）</title><link>https://pevenc12.github.io/posts/postgresql-explain-explained-scan/</link><pubDate>Tue, 29 Jun 2021 18:15:20 +0800</pubDate><guid>https://pevenc12.github.io/posts/postgresql-explain-explained-scan/</guid><description>前言 利用 EXPLAIN 指令對 SQL 進行效能分析相當的重要。除了確認資料庫內的索引（index）是否如預期被使用之外，再加上 ANALYZE ，更可以得到確切的執行流程與時間，由此來分析系統找出瓶頸。本文會先介紹 PostgreSQL 的三種掃描（SCAN）行為以及解說部分 Query Plan，下篇會再介紹各種聯合（JOIN）行為。
Scan Sequence Scan 會依序掃描所有硬碟中的 pages ，並找出符合查詢條件的資料（rows，行）。雖然聽起來很慢，但是在掃描的過程中會使用順序 I/O （Sequence I/O）而不是隨機 I/O （Random I/O），來提高速度。順序 I/O 的速度不管是在 HDD 上或是 SSD 上都明顯較快。
通常要避免資料庫進行全表查詢時，會加入索引來加快查詢的速度，此時就適用第二種查詢方式。
Index Scan 過程可以分為下列兩個步驟：
到索引產生的 B-Tree 中去找出符合查詢條件的鍵值對（key-value pairs），如圖一。 圖一。這張表已經以 so 欄位建立索引。以 SELECT &amp;hellip; FROM &amp;hellip; WHERE so &amp;gt; 250; 這句 SQL 為例。圖中的 page number 與 offset （0~7）為了方便理解而做了簡化。 在 B-Tree 中，資料儲存的格式為鍵值對。其中鍵（key）為建立索引時所使用的欄位資料。鍵經過排序之後，儲存在 B-Tree 中，因此可以快速地被找到。而值（key）則為該筆完整資料所在的位置，類似一個指標，指向某個 page （包含 page number 以及 offset）。 拿到鍵值對後，透過 page number 與 offset 去找出該 page 與上面的完整資料（rows）。 假如有多個查詢條件，並且都有建立 B-Tree 的話，就會反覆進行步驟一與步驟二。其中因為步驟二使用的是隨機 I/O ，如果執行太多次就會造成效能低落甚至不如使用 Sequence Scan 。</description></item></channel></rss>